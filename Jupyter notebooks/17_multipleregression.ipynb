{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. Multiple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially we'll be predicting house prices using 2 methods:\n",
    "\n",
    "1. MULTIPLE LINEAR REGRESSION\n",
    "\n",
    "This method involves creating a formula (linear regression) to predict the sale price of houses using multiple factors (attributes) such as the size of the first floor, second floor, garage area, etc.\n",
    "\n",
    "2. NEAREST NEIGHBOURS FOR REGRESSION\n",
    "\n",
    "An alternative approach where instead of using a formula, we predict the price of a house by looking at the prices of houses that are similar to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFnRFWHRUaXRsZQB2aXJpZGlzIGNvbG9ybWFwrE0mCwAAABx0RVh0RGVzY3JpcHRpb24AdmlyaWRpcyBjb2xvcm1hcAtjl3IAAAAwdEVYdEF1dGhvcgBNYXRwbG90bGliIHYzLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZw8V3hIAAAAydEVYdFNvZnR3YXJlAE1hdHBsb3RsaWIgdjMuOC4yLCBodHRwczovL21hdHBsb3RsaWIub3JnIbNBNQAAAiJJREFUeJzt1kGSmzAURdEv2FqWkP0vJfQgMhQCGceV2Ttn4pL0EVQPum771X5vVVXVWv39XfrPeV193V5zS98f1sf5/fPjey73zu6/3Hv/uz2cz57f9vP68rxO9+/zre7nhvvG+et6vH92bw3PDfcsD+eX59+/53n96f3362/f87/vf5yr93Of72/fPV9P89tX3zGeH3OT8/07Zs+/32+TuXZZD8/VODf8W5uuH/b7vctlfuv7NazH8/t7ZnP7bz2cD3NL+/Ph3Hl+/efz83vWun/vuL++nquH9eu9w/uu6/vvOO49f/8xf77vOj+8b7Y/fMfse9ca/y7nv+d62a++X+f1vt+G/b7u+/u6TxzzS//tc2053QMABBEAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAoB9ucImHxcKZtAAAAABJRU5ErkJggg==",
      "text/html": [
       "<div style=\"vertical-align: middle;\"><strong>viridis</strong> </div><div class=\"cmap\"><img alt=\"viridis colormap\" title=\"viridis\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFnRFWHRUaXRsZQB2aXJpZGlzIGNvbG9ybWFwrE0mCwAAABx0RVh0RGVzY3JpcHRpb24AdmlyaWRpcyBjb2xvcm1hcAtjl3IAAAAwdEVYdEF1dGhvcgBNYXRwbG90bGliIHYzLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZw8V3hIAAAAydEVYdFNvZnR3YXJlAE1hdHBsb3RsaWIgdjMuOC4yLCBodHRwczovL21hdHBsb3RsaWIub3JnIbNBNQAAAiJJREFUeJzt1kGSmzAURdEv2FqWkP0vJfQgMhQCGceV2Ttn4pL0EVQPum771X5vVVXVWv39XfrPeV193V5zS98f1sf5/fPjey73zu6/3Hv/uz2cz57f9vP68rxO9+/zre7nhvvG+et6vH92bw3PDfcsD+eX59+/53n96f3362/f87/vf5yr93Of72/fPV9P89tX3zGeH3OT8/07Zs+/32+TuXZZD8/VODf8W5uuH/b7vctlfuv7NazH8/t7ZnP7bz2cD3NL+/Ph3Hl+/efz83vWun/vuL++nquH9eu9w/uu6/vvOO49f/8xf77vOj+8b7Y/fMfse9ca/y7nv+d62a++X+f1vt+G/b7u+/u6TxzzS//tc2053QMABBEAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAoB9ucImHxcKZtAAAAABJRU5ErkJggg==\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#440154ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #440154ff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#fde725ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #fde725ff;\"></div></div>"
      ],
      "text/plain": [
       "<matplotlib.colors.ListedColormap at 0x25578460f80>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import libraries for regression\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Set style for seaborn plots\n",
    "sns.set_style('dark')\n",
    "sns.color_palette(\"viridis\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_price</th>\n",
       "      <th>1st_flr</th>\n",
       "      <th>2nd_flr</th>\n",
       "      <th>bsmt</th>\n",
       "      <th>garage</th>\n",
       "      <th>wood_deck</th>\n",
       "      <th>open_porch</th>\n",
       "      <th>lot</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215000</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>210</td>\n",
       "      <td>62</td>\n",
       "      <td>31770</td>\n",
       "      <td>1960</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sale_price  1st_flr  2nd_flr    bsmt  garage  wood_deck  open_porch    lot  \\\n",
       "0      215000     1656        0  1080.0   528.0        210          62  31770   \n",
       "\n",
       "   year_built  year_sold  \n",
       "0        1960       2010  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house = pd.read_csv('house.csv')\n",
    "house = house.rename(columns={\n",
    "    'SalePrice': 'sale_price',\n",
    "    '1st Flr SF': '1st_flr',\n",
    "    '2nd Flr SF': '2nd_flr',\n",
    "    'Total Bsmt SF': 'bsmt',\n",
    "    'Garage Area': 'garage',\n",
    "    'Wood Deck SF': 'wood_deck',\n",
    "    'Open Porch SF': 'open_porch',\n",
    "    'Lot Area': 'lot',\n",
    "    'Year Built': 'year_built',\n",
    "    'Yr Sold': 'year_sold'\n",
    "})\n",
    "house = house[['sale_price', '1st_flr', '2nd_flr', 'bsmt', 'garage', 'wood_deck', 'open_porch', 'lot', 'year_built', 'year_sold']]\n",
    "house.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram of sale prices shows a large amount of variability and a distribution that is clearly not normal. A long tail to the right contains a few houses that had very high prices. The short left tail does not contain any houses that sold for less than $35,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sale_price', ylabel='Count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAEmCAYAAAAKtqdLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApZklEQVR4nO3de1hU5d4+8HvAGDBElNMrUB7zhDiDIGqegiQNIQ2sdr5qvmrSJequ3B7QbabYxsQ8o+KrlW5LU0lTK8ttvbttmhrKuBVRQMURBJmfiikDo/D8/ijWZgRkOMiaBffnuuaKWc86fNeEN7PWetazVEIIASIihbKRuwAiorpgiBGRojHEiEjRGGJEpGgMMSJSNIYYESkaQ4yIFI0hRkSKxhAjIkVjiBGRojWTuwC5/b//9xt44xWRdVGpABeXFhbN2+RDTAgwxIgUjIeTRKRoDDEiUjSGGBEpGkOMiBSNIUZEisYQIyJFY4gRkaI1+X5iSmFr+5+/NyUlpTJWQmRdGGIKYGtrg8RjWcgtMOK/Wjogql9bBhnRHxhiCpFbYMS1W0a5yyCyOjwnRkSKxhAjIkVjiBGRojHEiEjRGGJEpGiyhlhWVhYmTpwIPz8/PPfcc9i0aZPUptfrMX78eGi1WoSGhuLIkSNmyx49ehRhYWHQaDQYN24c9Hp9Q5dPRFZAthArLS3F5MmT0apVK+zZswcLFy7E+vXrsX//fgghEB0dDVdXVyQlJWHEiBGYOnUqcnJyAAA5OTmIjo5GREQEdu/ejdatW2PKlCkQHN2QqMmRrZ+YwWBAt27d8P7778PR0RHt2rVDv379kJycDFdXV+j1euzYsQPNmzdHx44dcezYMSQlJWHatGnYtWsXevTogQkTJgAA4uLi0L9/f5w4cQJ9+vSRa5eISAayfRNzd3fHypUr4ejoCCEEkpOTcfLkSQQGBkKn06F79+5o3ry5NL+/vz9SUlIAADqdDgEBAVKbg4MDfHx8pHYiajqs4sR+cHAwRo8eDT8/PwwdOhT5+flwd3c3m8fFxQW5ubkAUG07ETUdVhFiq1evxoYNG3D+/HnExcXBaDTCzs7ObB47OzuYTCYAqLadiJoOq7h30tfXFwBQXFyMv/zlL4iMjITRaH6foMlkgr29PQBArVZXCCyTyQQnJ6eGKZiIrIZs38QMBgP+8Y9/mE3r1KkT7t+/Dzc3NxgMhgrzlx1Cenh4VNru5ub2eIsmIqsjW4hdu3YNU6dORV5enjTt7NmzaN26Nfz9/XHu3DkUFRVJbcnJydBoNAAAjUaD5ORkqc1oNCI1NVVqJ6KmQ7YQ8/X1hY+PD+bOnYuMjAz885//RHx8PN566y0EBgaiTZs2iImJQXp6OjZu3IgzZ85g1KhRAIDIyEicOnUKGzduRHp6OmJiYuDt7c3uFURNkGwhZmtri3Xr1sHBwQGvvfYa5s2bh7Fjx2LcuHFSW35+PiIiIrBv3z4kJCTA09MTAODt7Y01a9YgKSkJo0aNwu3bt5GQkACVSiXX7hCRTFSiiXdzNxh+g7V/Ara2Nlh4MA3Xbhnh3coBC4Z15ciu1KipVICrawuL5rWKLhZERLXFECMiRWOIEZGiMcSISNEYYkSkaAwxIlI0hhgRKRpDjIgUjSFGRIrGECMiRWOIEZGiMcSISNEYYkSkaAwxIlI0hhgRKRpDjIgUjSFGRIrGECMiRWOIEZGiMcSISNEYYkSkaAwxIlI0hhgRKZqsIZaXl4fp06cjMDAQAwcORFxcHIqLiwEAixcvRpcuXcxe27Ztk5Y9cOAAhgwZAo1Gg+joaNy8eVOu3WhQNirAxkYFW1sb6UXUlDWTa8NCCEyfPh1OTk747LPPUFBQgLlz58LGxgazZ89GZmYmZsyYgZdffllaxtHREQBw5swZzJs3DwsXLkTXrl3xwQcfICYmBomJiXLtToNxa2GPDT9n4XpBIQDgv1o6IKpfWz5Ml5os2ULs0qVLSElJwc8//wxXV1cAwPTp0/Hhhx9KITZx4kS4ublVWHbbtm148cUXMXLkSADA0qVLERQUBL1ej6eeeqohd0MWuQVGXLtllLsMIqsg27GIm5sbNm3aJAVYmbt37+Lu3bvIy8tDu3btKl1Wp9MhICBAet+mTRt4enpCp9M9zpKJyArJFmJOTk4YOHCg9L60tBTbtm1D3759kZmZCZVKhQ0bNmDQoEF46aWXsGfPHmneGzduwN3d3Wx9Li4uyM3NbbD6G0LZOS8bG5XcpRBZLdkOJx8WHx+P1NRU7N69G+fOnYNKpUKHDh0wZswYnDx5EvPnz4ejoyNCQkJQVFQEOzs7s+Xt7OxgMplkqr7+2draIPFYFnILjPDxagkVGGRElbGKEIuPj8eWLVuwYsUKdO7cGc888wyCgoLg7OwMAOjatSuuXLmC7du3IyQkBGq1ukJgmUwmODg4yFD941N27svDyV7uUoisluzX52NjY/HJJ58gPj4eQ4cOBQCoVCopwMp06NABeXl5AAAPDw8YDAazdoPBUOlFACJq3GQNsbVr12LHjh1Yvnw5hg8fLk1ftWoVxo8fbzZvWloaOnToAADQaDRITk6W2q5fv47r169Do9E0SN1EZD1kC7HMzEysW7cOb775Jvz9/ZGfny+9goKCcPLkSWzevBlXr17F559/jr1792LChAkAgNdffx1fffUVdu3ahbS0NMyaNQvPPfdck+heQUTmZDsndvjwYZSUlGD9+vVYv369WduFCxewatUqrF69GqtWrYKXlxc++ugj+Pn5AQD8/PywaNEirF69GgUFBejfvz9iY2Pl2A0ikplKCCHkLkJOBsNvsMZPwNbWBgsPpuHaLSP827bCjTvF0N8qNPsZALxbOWDBsK7ssU+NikoFuLq2sGhe2U/sExHVBUOMiBSNIUZEisYQIyJFY4gRkaIxxIhI0RhiRKRoDDEiUjSGGBEpGkOMiBTNKsYTo9ore/pR2d8j3n5ETQ1DTOHKP/2ITz6ipogh1gjw6UfUlPGcGBEpGkOMiBSNIUZEisYQIyJFY4gRkaIxxIhI0RhiRKRoDDEiUjSGGBEpmqwhlpeXh+nTpyMwMBADBw5EXFwciouLAQB6vR7jx4+HVqtFaGgojhw5Yrbs0aNHERYWBo1Gg3HjxkGv18uxC0QkM9lCTAiB6dOnw2g04rPPPsOKFSvw448/YuXKlRBCIDo6Gq6urkhKSsKIESMwdepU5OTkAABycnIQHR2NiIgI7N69G61bt8aUKVPQxB+hSdQkyXbv5KVLl5CSkoKff/4Zrq6uAIDp06fjww8/xKBBg6DX67Fjxw40b94cHTt2xLFjx5CUlIRp06Zh165d6NGjByZMmAAAiIuLQ//+/XHixAn06dNHrl0iIhnI9k3Mzc0NmzZtkgKszN27d6HT6dC9e3c0b95cmu7v74+UlBQAgE6nQ0BAgNTm4OAAHx8fqZ2Img7ZQszJyQkDBw6U3peWlmLbtm3o27cv8vPz4e7ubja/i4sLcnNzAaDadiJqOqzm6mR8fDxSU1PxzjvvwGg0ws7Ozqzdzs4OJpMJAKptJ6KmwypCLD4+Hlu2bEF8fDw6d+4MtVpdIZBMJhPs7e0BoMp2BweHBquZiKyD7CEWGxuLTz75BPHx8Rg6dCgAwMPDAwaDwWw+g8EgHUJW1e7m5tYwRROR1ZA1xNauXYsdO3Zg+fLlGD58uDRdo9Hg3LlzKCoqkqYlJydDo9FI7cnJyVKb0WhEamqq1N5UlY23b2trA1tb2f8+ETUI2X7TMzMzsW7dOrz55pvw9/dHfn6+9AoMDESbNm0QExOD9PR0bNy4EWfOnMGoUaMAAJGRkTh16hQ2btyI9PR0xMTEwNvbu8l3rygbb3/hwTQkHstikFGTINtv+eHDh1FSUoL169djwIABZi9bW1usW7cO+fn5iIiIwL59+5CQkABPT08AgLe3N9asWYOkpCSMGjUKt2/fRkJCAlQqlVy7YzXKxtu/ccdo9q2MgUaNlUrUczf3mzdvonXr1vW5ysfKYPgN1tjR39bWBgsPpuHaLSP827bCjTvF0N8qNPsZQJVt/m1bwUZlg+sFv8/HJyGRkqhUgKtrC4vmrdWf527duuHmzZsVpmdnZ+P555+vzSrpMSj7VnbtlhG5BXwaEjVOFt92tHfvXnz55ZcAIN3b+MQTT5jNc+PGDV4hJKIGZXGIhYSE4Nq1awCAEydOQKvV4sknnzSbp3nz5ggJCanfComIHsHiEHvyyScxdepUAICXlxdCQ0OhVqsfW2FERJao1SgWL7/8MrKysnD27Fncv3+/QvvIkSPrWhcRkUVqFWKbNm3CsmXL0LJlywqHlCqViiFGRA2mViH28ccfY+bMmZg4cWJ910NEVCO16mJRXFyMF154ob5rISKqsVqFWHh4OD7//HMOB01EsqvV4eTdu3exe/duHDhwAN7e3hX6i23durVeiiMiqk6tQqxdu3Z466236rsWIqIaq1WIlfUXIyKSW61CLCYm5pHtcXFxtSqGiKim6mV8lgcPHuDy5cv45ptvFDWCBREpX62+iVX1TWvTpk24ePFinQoiIqqJeh0pb9iwYTh06FB9rpKI6JHq7QnghYWF2LlzJ1q1alVfq2ySykZgtbHhKLVElqhViHXt2rXSoaDVajUWL15c56KaKltbGyQey0JugRE+Xi2hAoOMqDq1CrGHO7OqVCo88cQT6NSpExwdHeulsKaqbDRWDyd7uUshUoRahVhgYCAA4MqVK8jMzERpaSnat2/PACOiBlerELtz5w5iYmJw+PBhtGzZEiUlJbh37x569+6NhIQEtGhh2QD/RER1Vaurk4sXL0Zubi6++eYbHD9+HL/++iv279+PwsJCdnQlogZVqxD74Ycf8P7776NDhw7StE6dOuG9997D4cOH6604IqLq1CrE1Go1bGwqLqpSqVBSUlLj9ZlMJoSFheH48ePStMWLF6NLly5mr23btkntBw4cwJAhQ6DRaBAdHV3pI+SIqPGrVYgFBwdj4cKFuHr1qjTtypUrWLx4MQYPHlyjdRUXF+Pdd99Fenq62fTMzEzMmDEDR44ckV6RkZEAgDNnzmDevHmYOnUqvvjiC+kcHRE1PbU6sT9z5kxER0dj6NChcHJyAgAUFBRg0KBBmD9/vsXrycjIwIwZMyodXDEzMxMTJ06s9DmW27Ztw4svviiN5b906VIEBQVBr9fjqaeeqs0uEZFC1TjEsrKy4Onpib///e+4cOECMjMzoVar0a5dO3Ts2LFG6zpx4gT69OmDd955B1qtVpp+9+5d5OXloV27dpUup9Pp8Oabb0rv27RpA09PT+h0OoYYURNj8eGkEAKLFy/Giy++iNOnTwMAunTpgtDQUCQlJSEsLAxLliyp0ZDVo0ePxty5c+Hg4GA2PTMzEyqVChs2bMCgQYPw0ksvYc+ePVL7jRs34O7ubraMi4sLcnNzLd52U2Oj+v1WJltbG+nWJqLGwOJvYlu3bsU333yDhIQEqbNrmXXr1uGHH35ATEwMnn76aYwePbpORV26dAkqlQodOnTAmDFjcPLkScyfPx+Ojo4ICQlBUVER7OzszJaxs7ODyWSq03YbM7cW9tjwcxauFxTiv1o6IKpfW5SUlMpdFlGdWRxiO3fuxPz58xEUFFRpe3BwMP7yl79g69atdQ6xkSNHIigoCM7OzgB+v1fzypUr2L59O0JCQqBWqysElslkqvCNjsyV3dJE1JhYfFyRnZ2Nnj17PnKevn37Qq/X17kolUolBViZDh06IC8vDwDg4eEBg8Fg1m4wGCq9CEBEjZvFIebi4oLs7OxHzpObm1shfGpj1apVGD9+vNm0tLQ0qXOtRqNBcnKy1Hb9+nVcv34dGo2mztsmImWxOMRCQkKwZs0a3L9/v9L2Bw8eYO3atRgwYECdiwoKCsLJkyexefNmXL16FZ9//jn27t2LCRMmAABef/11fPXVV9i1axfS0tIwa9YsPPfcc7wySdQEWXxObMqUKRg1ahQiIiIwduxY9OjRAy1atEBBQQHOnTuHbdu24d69e1i6dGmdi+rZsydWrVqF1atXY9WqVfDy8sJHH30EPz8/AICfnx8WLVqE1atXo6CgAP3790dsbGydt0tEymNxiDk5OWHnzp1YtmwZlixZAqPx9xPEQgi0aNECoaGhmDZtGlxdXWtVyIULF8zeDxkyBEOGDKly/oiICERERNRqW0TUeNSos6uzszMWL16M9957D3q9Hnfu3IGzszOefvpp2NraPq4aiYiqVKvbjuzs7GrcO5+I6HFg120iUjSGGBEpGkOMiBSNIUZEisYQIyJFY4gRkaIxxIhI0RhiRKRoDDEiUjSGGBEpGkOMiBStVvdOUuPy8INDOPY+KQlDrImztbVB4rEs5Bb8PrQSHyJCSsMQIz5AhBSN58SISNEYYkSkaDycbILKngYO2PzxXyLlYog1QeWfBu7j1RIqMMhIuXg42USVncw3/FYsdylEdcIQIyJFs4oQM5lMCAsLw/Hjx6Vper0e48ePh1arRWhoKI4cOWK2zNGjRxEWFgaNRoNx48ZBr9c3dNlEZAVkD7Hi4mK8++67SE9Pl6YJIRAdHQ1XV1ckJSVhxIgRmDp1KnJycgAAOTk5iI6ORkREBHbv3o3WrVtjypQpEELItRtEJBNZQywjIwOvvvoqrl69ajb9l19+gV6vx6JFi9CxY0dERUVBq9UiKSkJALBr1y706NEDEyZMwDPPPIO4uDhkZ2fjxIkTcuxGndja2kgvXikkqjlZr06eOHECffr0wTvvvAOtVitN1+l06N69O5o3by5N8/f3R0pKitQeEBAgtTk4OMDHxwcpKSno06dPQ5VfZw/f8sMrhUQ1J2uIjR49utLp+fn5cHd3N5vm4uKC3Nxci9qVpPwtPx5O9jJXQ6Q8sp8Tq4zRaISdnZ3ZNDs7O5hMJovaiajpsMoQU6vVFQLJZDLB3t7+ke0ODg4NViMRWQerDDEPDw8YDAazaQaDQTqErKrdzc2twWokIutglSGm0Whw7tw5FBUVSdOSk5Oh0Wik9uTkZKnNaDQiNTVVaieipsMqQywwMBBt2rRBTEwM0tPTsXHjRpw5cwajRo0CAERGRuLUqVPYuHEj0tPTERMTA29vb0VdmSSi+mGVIWZra4t169YhPz8fERER2LdvHxISEuDp6QkA8Pb2xpo1a5CUlIRRo0bh9u3bSEhIgErF7glETY3VjGJx4cIFs/dt27bFtm3bqpx/8ODBGDx48OMuq8kpP0wPwPH2yfpZTYiRdSg/TA/H2yclYIhRBRxzn5SEISaDskek8V5JorpjiDWw8vdL8l5JorqzyquTjR1HVSWqPwwxIlI0hhgRKRpDjIgUjSf2qUrs+EpKwBCjKrHjKykBQ4weiR1fydoxxMgiPLQka8UQI4vw0JKsFUOMLMZDS7JG7GJBRIrGECMiRWOIEZGiMcSISNEYYkSkaAwxIlI0hhgRKRpDjIgUjSFGRIpm1SF26NAhdOnSxew1ffp0AEBqaipeeeUVaDQaREZG4uzZszJXS0RysOrbjjIyMhAUFITY2FhpmlqtRmFhISZPnozw8HAsWbIE27dvR1RUFA4dOoTmzZvLWHHVGtMTjh6+GfxhvKeSGpJVh1hmZiY6d+4MNzc3s+m7d++GWq3GrFmzoFKpMG/ePPz00084ePAgIiIiZKq2ao3tCUflbwYHAB+vlrh59z5vDidZWPXhZGZmJtq1a1dhuk6ng7+/P1Sq38NApVKhV69eSElJadgCa6CxPeGobH/K9qnsfW4BbxCnhmW1ISaEwOXLl3HkyBEMHToUQ4YMwbJly2AymZCfnw93d3ez+V1cXJCbmytTtUQkF6s9nMzJyYHRaISdnR1WrlyJa9euYfHixSgqKpKml2dnZweTySRTtVSGgydSQ7PaEPPy8sLx48fRsmVLqFQqdOvWDaWlpZg5cyYCAwMrBJbJZIK9vb1M1VIZDp5IDc1qQwwAnJ2dzd537NgRxcXFcHNzg8FgMGszGAwVDjFJHpYOnlh2xRbgNzaqPas9J/avf/0Lffr0gdH4n38M58+fh7OzM/z9/XH69GkIIQD8fv7s1KlT0Gg0cpVLNVR2xXbhwTQkHssyCzSimrDa3xw/Pz+o1Wr89a9/xaVLl/DPf/4TS5cuxaRJkzBs2DDcuXMHH3zwATIyMvDBBx/AaDTixRdflLtsqgFe0aT6YLUh5ujoiM2bN+PmzZuIjIzEvHnz8Nprr2HSpElwdHREYmIikpOTERERAZ1Oh40bN1ptR1cienys+pzYM888g08++aTStp49e2LPnj0NXBERWRur/SZGRGQJhhgRKRpDjIgUjSFGRIrGECMiRbPqq5OkbJWNO8ae+VTfGGL02Dw87hjvpaTHgSH2mJS/jaYxjOZaW5beR0lUWwyxx6D8SK4AGsVorkTWiiH2mJT/BuLhxCGCiB4XXp0kIkVjiBGRovFwkmTHrhhUFwwxajDlw6r8FdvadsV4eCBFBl/TxBCjBlM+rB6+YlvTrhgPXwFmH7SmiyFGDaosrOrjii37oBHAECMFsOSBInxUXNPFECOr8/C5s/U/X0FugfGRh4x8VFzTxRCrR2XfGJrybUb14eFzZ3kFRRYdNvLwsmliiNWT8ieaeZtR3dXnuTNexWzcGGL1qD7/4VFFVXXReBRexWz8GGKkGI/qolHew2HHw8zGjSFWRzwP1rAs+bb7qLDjVczGR9EhVlxcjIULF+L777+Hvb09JkyYgAkTJjTY9nkezHpVFXaPuor58LmzqjD4rIuiQ2zp0qU4e/YstmzZgpycHMyePRuenp4YNmxYg9XA82DKU9nhZWVjwN28e1/6Nlf2M8+pWR/FhlhhYSF27dqF//3f/4WPjw98fHyQnp6Ozz77rN5DrKq/0DyEVLZHnTvzcLLHjTvF0h+osp+ru1ndko65D89XnqXLPDyfpduVw+OuTbEhlpaWhgcPHsDPz0+a5u/vjw0bNqC0tBQ2NvUzytDDh4xlf5EBjtiqdJZeKKhqGQBo4+yAt55th9JSYXHH3Kp+pyxdprLD4LK28vUA8gfao+quL4oNsfz8fLRq1Qp2dnbSNFdXVxQXF+P27dto3bq1RetRWZBBds1soG5mgydsVdLPAPCErQpPuzwJu2YqtHG2h/0TzSr8DKDKttrM9zjX3RRruHXvgfT/tuz/ZXXrK1sGADyc1Pj6/A0Y7hajveuTUDezhbqZDeya2VT4xlbGxuY/v0flf6csXebh+cq3la/HxdEOYd08pECTw8N1A5b9m7NknjKKDTGj0WgWYACk9yaTyeL1uLi0qHaeGUO71qw4omrU5nfqUctY8+/o465NsSO7qtXqCmFV9t7enifZiZoKxYaYh4cHbt26hQcPHkjT8vPzYW9vDycnJxkrI6KGpNgQ69atG5o1a4aUlBRpWnJyMnx9fevtpD4RWT/F/mt3cHDAyJEj8f777+PMmTP4xz/+gY8//hjjxo2TuzQiakAqIYR8ly7qyGg04v3338f3338PR0dHTJw4EePHj5e7LCJqQIoOMSIixR5OEhEBDDEiUjiGGBEpGkOsnOLiYsydOxcBAQEYMGAAPv74Y7lLAgDk5eVh+vTpCAwMxMCBAxEXF4fi4mIAgF6vx/jx46HVahEaGoojR46YLXv06FGEhYVBo9Fg3Lhx0Ov1Zu2ffvopBg4cCD8/P8ydOxdG439Gd6ju86hu27UxefJkzJkzR3qfmpqKV155BRqNBpGRkTh79qzZ/AcOHMCQIUOg0WgQHR2NmzdvSm1CCCxbtgx9+/ZFYGAgli5ditLS/9y3d+vWLUybNg1+fn4IDg7GV199Zbbu6rZdUyaTCQsXLkTv3r3x7LPPYvny5Sg7Jd2Y9rPBCZIsWrRIhIeHi7Nnz4rvv/9e+Pn5iW+//VbWmkpLS8Wrr74qJk2aJC5evChOnjwpQkJCxJIlS0RpaakIDw8XM2bMEBkZGWLDhg1Co9GI7OxsIYQQ2dnZQqvVis2bN4uLFy+KP//5zyIsLEyUlpYKIYQ4ePCg8Pf3Fz/88IPQ6XQiNDRULFy4UNr2oz6P6rZdGwcOHBCdO3cWs2fPFkIIce/ePdG/f3+xZMkSkZGRIWJjY8Wzzz4r7t27J4QQQqfTiZ49e4o9e/aI8+fPizFjxojJkydL69u8ebMYPHiwOHnypDh27JgYMGCA2LRpk9QeFRUl3njjDXHhwgWxc+dO0aNHD6HT6Szadm3Mnz9fvPDCC0Kn04mjR4+KPn36iO3btze6/WxoDLE/3Lt3T/j6+opffvlFmpaQkCDGjBkjY1VCZGRkiM6dO4v8/Hxp2v79+8WAAQPE0aNHhVarNfuFe+ONN8Tq1auFEEKsXLnSrP7CwkLh5+cn7ePo0aOleYUQ4uTJk6Jnz56isLCw2s+jum3X1K1bt8SgQYNEZGSkFGK7du0SwcHBUuiWlpaKkJAQkZSUJIQQYubMmdK8QgiRk5MjunTpIq5evSqEEGLw4MHSvEIIsXfvXhEUFCSEECIrK0t07txZ6PV6qX3u3LkWb7s2+9e9e3dx/PhxaVpiYqKYM2dOo9pPOfBw8g9VDe2j0+nMvpo3NDc3N2zatAmurq5m0+/evQudTofu3bujefPm0nR/f3/pLgadToeAgACpzcHBAT4+PkhJSUFJSQn+/e9/m7VrtVrcv38faWlp1X4e1W27pj788EOMGDECnTp1kqbpdDr4+/tD9ceQBiqVCr169apy/9q0aQNPT0/odDrk5eXh+vXr6N27t1l92dnZuHHjBnQ6Hdq0aQNvb2+z9tOnT1u07ZpKTk6Go6MjAgMDpWmTJ09GXFxco9pPOTDE/lDd0D5ycXJywsCBA6X3paWl2LZtG/r27Yv8/Hy4u7ubze/i4oLc3FwAeGT7nTt3UFxcbNberFkzODs7Izc3t9rPo7pt18SxY8fw66+/YsqUKWbTq9vGjRs3qmzPz88HALP2sj8EZe2VLZuXl2fRtmtKr9fDy8sLe/fuxbBhw/D8888jISEBpaWljWo/5aDYoXjqW30N7fO4xcfHIzU1Fbt378ann35aac1l9Va1TyaTCUVFRdL7ytqFEI/8PB617pooLi7GggUL8N5771UYfaS6bRQVFdVo/2pSf33tX5nCwkJkZWVhx44diIuLQ35+Pt577z04ODg0qv2UA0PsD0oY2ic+Ph5btmzBihUr0LlzZ6jV6grfEk0mk1RvVfvk5OQEtVotvX+43cHBASUlJY/8PKrbtqXWrl2LHj16mH3bLFNV/dXtn4ODg9k/5If31cHBodbrru3vQrNmzXD37l189NFH8PLyAgDk5ORg+/btaNu2baPZTzkwxP5QfmifZs1+/1isaWif2NhYbN++HfHx8Rg6dCiA32vOyMgwm89gMEiHBx4eHjAYDBXau3XrBmdnZ6jVahgMBnTs2BEA8ODBA9y+fRtubm4QQjzy86hu25b6+uuvYTAYpHNvZf+gvvvuO4SFhVVaf3X75+bmBg8PD6nmsvNBZYdeZe1VLfuoddd0/8q4ublBrVZLAQYA7du3x/Xr1xEYGNho9lMOPCf2B2se2mft2rXYsWMHli9fjuHDh0vTNRoNzp07Jx1SAL/XrNFopPbk5GSpzWg0IjU1FRqNBjY2NvD19TVrT0lJQbNmzdC1a9dqP4/qtm2pv//979i/fz/27t2LvXv3Ijg4GMHBwdi7dy80Gg1Onz4t9aUSQuDUqVNV7t/169dx/fp1aDQaeHh4wNPT06w9OTkZnp6ecHd3h1arRXZ2ttm5n+TkZGi1Wmndj9p2TWk0GhQXF+Py5cvStEuXLsHLy6tR7acs5Losao3mz58vhg8fLnQ6nTh06JDo1auX+O6772StKSMjQ3Tr1k2sWLFC3Lhxw+z14MEDERoaKt5++21x8eJFkZiYKLRardRXS6/XC19fX5GYmCj1EwsPD5cupx84cED06tVLHDp0SOh0OjF8+HARGxsrbftRn0d1266t2bNnS5f/f/vtN9G3b18RGxsr0tPTRWxsrOjfv7/UrePUqVPCx8dH7Ny5U+o/FRUVJa0rMTFRDBgwQPzyyy/il19+EQMGDBAff/yx1D5hwgQxZswYcf78ebFz507h6+sr9Z+qbtu1MXnyZPHaa6+J8+fPi59++kn07dtXbNmypdHtZ0NjiJVTWFgoZs2aJbRarRgwYID45JNP5C5JJCYmis6dO1f6EkKIK1euiP/+7/8WPXr0EMOHDxc///yz2fL/93//J1544QXRs2dP8cYbb0h9i8qvv1+/fsLf31/ExMSIoqIiqa26z6O6bddG+RAT4veOniNHjhS+vr5i1KhR4ty5c2bzJyUlicGDBwutViuio6PFzZs3pbYHDx6Iv/3tbyIgIED06dNHxMfHSwEuhBAGg0FERUUJX19fERwcLPbv32+27uq2XVN37twRM2fOFFqtVvTr10+sWbNGqqcx7WdD41A8RKRoPCdGRIrGECMiRWOIEZGiMcSISNEYYkSkaAwxIlI0hhgRKRpDjKzCmjVrMHbsWFm2PWfOHLMhsUlZeAM4NXnz5s2TuwSqA4YYNXktWrSQuwSqAx5OUr3bunUrgoKC4Ovri4iICPz6668AgMOHD2PkyJHw9fVFQEAA3n33Xdy7d6/Sdfz666+IiIhAz549ER4eju+++87i7QcHB+PTTz9FeHg4tFotJk+eLA1Pc/z4cQQHB2PBggXw9/fHxo0bKxxOfvXVVxg2bBg0Gg3+9Kc/ITU1VWrbsWMHgoOD4efnh7Fjx+LChQu1+YioHjHEqF6lpqZi6dKlWLBgAb799lsEBATg7bffxtWrV/HnP/8Zo0ePxrfffouVK1fi6NGj2LlzZ4V15OfnIyoqChEREdi/fz8mTZqEOXPmSGFoiTVr1mDSpEn44osvYDQaMW3aNKktOzsbJpMJX375JcLCwsyW+9e//oV58+bhjTfewL59+9CjRw9ERUXBZDLhhx9+wNq1azF//nzs2bMH/v7+GDduHAoKCmr/gVGd8XCS6lV2djZUKhU8PT3h7e2Nt99+G0FBQSgtLcVf//pXvPrqqwAAb29vPPvss0hPT6+wjs8++wzPPvssxowZAwBo27Ytzp8/jy1btpg9MONRIiMjMWLECADA3/72NwwZMgQXL16U2idNmoS2bdtWWO6LL75AWFgYXn/9dQDArFmz8MQTT6CgoACbNm1CVFQUgoKCAABvv/02fvrpJ+zbt0+2ixLEEKN6NmDAAHTu3Bnh4eHo3r07nn/+ebzyyivw8PCAnZ0d1q9fj/T0dKSnpyMjI0MKmvIuXbqEH3/80exJS/fv30f79u0trqNXr17Sz0899RScnZ2RmZmJ1q1bA4DZ03/Ku3z5Mv70pz9J7+3s7DB79mwAQGZmJuLj47F8+XKpvbi4GFeuXLG4Lqp/DDGqVw4ODti1axdOnDiBH3/8EV9++SW2b9+OFStWICoqCsHBwQgICMD48eOxZcuWStfx4MEDhIeH46233jKbXjZMtiUenrekpMRshN6y8eirW+7hdcydOxf9+vUzm+7o6GhxXVT/eE6M6tXp06eRmJiIvn37IiYmBgcPHkRxcTHmzJmD3r1746OPPsLo0aPRs2dPZGVlobLh7Nq3b4+srCy0bdtWeh0+fBj79++3uI60tDTp56ysLPz222/o0qVLtcu1bdvWbNmSkhIEBwcjOTkZ7du3R25urlldGzZsUNQzGhsjhhjVK3t7eyQkJGDXrl24du0avv76axQWFuK1117DhQsXcObMGVy+fBlLlizBv//970ofDTZ69GicPXsWK1aswJUrV7B//34sX74cnp6eFtexdetWHD58GGlpaZg7dy769++Pdu3aVbvc2LFjsW/fPuzZswdZWVmIi4uDEAI+Pj74n//5H2zZsgV79+7F1atXER8fj2+//VZ60ArJg4eTVK+6deuGDz74AOvWrcOiRYvg6emJ+Ph4BAUFITU1FePHj4darUbv3r0RHR2Nr7/+usI6vLy8sGHDBixbtgybN2+Gh4cH5syZg5deesniOl5++WUsX74cOTk5GDx4MBYuXGjRcr1798aCBQuQkJCA/Px89OjRAxs2bIC9vT1CQ0NhMBiwevVqGAwGdOrUCevXr7coHOnx4fDU1OgEBwdj6tSpiIiIkLsUagA8nCQiRePhJClKdHQ0jh49WmW7pYeN1HjwcJIU5caNGzAajVW2u7i4sMtDE8MQIyJF4zkxIlI0hhgRKRpDjIgUjSFGRIrGECMiRWOIEZGiMcSISNEYYkSkaP8f1WBujRDALk8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (3, 3))\n",
    "sns.histplot(data = house,\n",
    "             x = 'sale_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (3, 3))\n",
    "sns.histplot(data = house,\n",
    "    kdfkdfkhd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_price</th>\n",
       "      <th>1st_flr</th>\n",
       "      <th>2nd_flr</th>\n",
       "      <th>bsmt</th>\n",
       "      <th>garage</th>\n",
       "      <th>wood_deck</th>\n",
       "      <th>open_porch</th>\n",
       "      <th>lot</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sale_price</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6217</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.6404</td>\n",
       "      <td>0.3271</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>-0.0306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sale_price  1st_flr  2nd_flr    bsmt  garage  wood_deck  \\\n",
       "sale_price         1.0   0.6217   0.2694  0.6323  0.6404     0.3271   \n",
       "\n",
       "            open_porch     lot  year_built  year_sold  \n",
       "sale_price       0.313  0.2665      0.5584    -0.0306  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house.corr().head(1).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, combining attributes can provide higher correlation. In particular, if we sum the first floor and second floor areas, the result has a higher correlation than any single attribute alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_shuffled = house.sample(frac = 1, replace = False)\n",
    "split_index = len(house_shuffled) // 2\n",
    "training_set = house_shuffled[:split_index]\n",
    "testing_set = house_shuffled[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Understanding how slopes = weights & their affects on predicted y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'sale_price' is the correct column name, but make sure to check the actual column names in your DataFrame.\n",
    "example_row = house.drop(['sale_price'], axis=1).iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using slopes: [ 9.77581339  9.34694567  9.5111019  11.45980413 11.27927041  9.70169537\n",
      "  9.46341875 10.62225996  8.62286476]\n"
     ]
    }
   ],
   "source": [
    "example_slopes = np.random.normal(10, 1, len(example_row))\n",
    "print('Using slopes:', example_slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(slopes, row):\n",
    "    return sum(slopes * np.array(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict function takes these slopes and multiplies them by the corresponding attribute values in example_row. The sum of these products gives the estimated sale price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual sale price: 215000\n",
      "Predicted sale price using random slopes: 374286.06691360136\n"
     ]
    }
   ],
   "source": [
    "print('Actual sale price:', house['sale_price'].iloc[0])\n",
    "print('Predicted sale price using random slopes:', predict(example_slopes, example_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is an estimated sale price, which can be compared to the actual sale price to assess whether the slopes provide accurate predictions. Since the example_slopes above were chosen at random, we should not expect them to provide accurate predictions at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Least square regressions\n",
    "\n",
    "The next step in performing multiple regression is to define the least squares objective. We perform the prediction for each row in the training set, and then compute the root mean squared error (RMSE) of the predictions from the actual prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89087.32460321065"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'training_set' is your training DataFrame\n",
    "train_prices = training_set['sale_price'].values\n",
    "train_attributes = training_set.drop(['sale_price'], axis=1)\n",
    "\n",
    "train_attributes_filled = train_attributes.fillna(train_attributes.mean())\n",
    "\n",
    "# Ensure example_slopes matches the number of remaining attributes\n",
    "example_slopes = np.random.normal(10, 1, len(train_attributes.columns))\n",
    "\n",
    "def predict(slopes, row):\n",
    "    return sum(slopes * np.array(row))\n",
    "\n",
    "def rmse(slopes, attributes, prices):\n",
    "    errors = [(predict(slopes, attributes.iloc[i, :]) - prices[i]) ** 2 for i in range(len(prices))]\n",
    "    return np.sqrt(np.mean(errors))\n",
    "\n",
    "def rmse_train(slopes):\n",
    "    return rmse(slopes, train_attributes_filled, train_prices)\n",
    "\n",
    "rmse_train(example_slopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the minimize function to find the slopes with the lowest RMSE. Since the function we want to minimize, rmse_train, takes an array instead of a number, we must pass the array=True argument to minimize. When this argument is used, minimize also requires an initial guess of the slopes so that it knows the dimension of the input array. Finally, to speed up optimization, we indicate that rmse_train is a smooth function using the smooth=True attribute. Computation of the best slopes may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best slopes for the training set:\n",
      "1st_flr\t66.81014125551881\n",
      "2nd_flr\t65.5419655100946\n",
      "bsmt\t29.030078327882073\n",
      "garage\t58.75061686291079\n",
      "wood_deck\t49.2644691605095\n",
      "open_porch\t21.072327502542507\n",
      "lot\t0.5483520154972276\n",
      "year_built\t732.6400176420666\n",
      "year_sold\t-713.8968896496317\n",
      "RMSE of all training examples using the best slopes: 42441.05549506805\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Set bounds for the slopes, if needed\n",
    "bounds = [(None, None)] * len(example_slopes)\n",
    "\n",
    "# Use minimize to find the best slopes\n",
    "best_slopes = minimize(rmse_train, x0=example_slopes, bounds=bounds)['x']\n",
    "\n",
    "# Display the best slopes\n",
    "print('The best slopes for the training set:')\n",
    "for label, slope in zip(train_attributes.columns, best_slopes):\n",
    "    print(f'{label}\\t{slope}')\n",
    "\n",
    "# Calculate and display the RMSE using the best slopes\n",
    "best_rmse = rmse_train(best_slopes)\n",
    "print('RMSE of all training examples using the best slopes:', best_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Existing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>sale_price</td>    <th>  R-squared:         </th> <td>   0.737</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.736</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   907.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 08 Jan 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:37:58</td>     <th>  Log-Likelihood:    </th> <td> -35252.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2928</td>      <th>  AIC:               </th> <td>7.052e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2918</td>      <th>  BIC:               </th> <td>7.058e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>-1.184e+05</td> <td> 1.16e+06</td> <td>   -0.102</td> <td> 0.919</td> <td>-2.39e+06</td> <td> 2.16e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"1st_flr\")</th> <td>   71.8469</td> <td>    3.497</td> <td>   20.546</td> <td> 0.000</td> <td>   64.990</td> <td>   78.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"2nd_flr\")</th> <td>   68.3078</td> <td>    2.006</td> <td>   34.053</td> <td> 0.000</td> <td>   64.375</td> <td>   72.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bsmt</th>         <td>   38.6885</td> <td>    3.018</td> <td>   12.818</td> <td> 0.000</td> <td>   32.770</td> <td>   44.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garage</th>       <td>   62.7917</td> <td>    4.631</td> <td>   13.559</td> <td> 0.000</td> <td>   53.711</td> <td>   71.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wood_deck</th>    <td>   38.5272</td> <td>    6.378</td> <td>    6.041</td> <td> 0.000</td> <td>   26.022</td> <td>   51.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>open_porch</th>   <td>   14.9671</td> <td>   12.141</td> <td>    1.233</td> <td> 0.218</td> <td>   -8.839</td> <td>   38.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lot</th>          <td>    0.3054</td> <td>    0.104</td> <td>    2.934</td> <td> 0.003</td> <td>    0.101</td> <td>    0.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year_built</th>   <td>  679.6490</td> <td>   30.102</td> <td>   22.578</td> <td> 0.000</td> <td>  620.626</td> <td>  738.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year_sold</th>    <td> -609.9535</td> <td>  576.727</td> <td>   -1.058</td> <td> 0.290</td> <td>-1740.787</td> <td>  520.880</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1242.185</td> <th>  Durbin-Watson:     </th>  <td>   1.454</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>135089.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-1.030</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>36.212</td>  <th>  Cond. No.          </th>  <td>2.01e+07</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.01e+07. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &   sale\\_price    & \\textbf{  R-squared:         } &     0.737   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.736   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     907.6   \\\\\n",
       "\\textbf{Date:}             & Mon, 08 Jan 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     15:37:58     & \\textbf{  Log-Likelihood:    } &   -35252.   \\\\\n",
       "\\textbf{No. Observations:} &        2928      & \\textbf{  AIC:               } & 7.052e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &        2918      & \\textbf{  BIC:               } & 7.058e+04   \\\\\n",
       "\\textbf{Df Model:}         &           9      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                       & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}     &   -1.184e+05  &     1.16e+06     &    -0.102  &         0.919        &    -2.39e+06    &     2.16e+06     \\\\\n",
       "\\textbf{Q(\"1st\\_flr\")} &      71.8469  &        3.497     &    20.546  &         0.000        &       64.990    &       78.703     \\\\\n",
       "\\textbf{Q(\"2nd\\_flr\")} &      68.3078  &        2.006     &    34.053  &         0.000        &       64.375    &       72.241     \\\\\n",
       "\\textbf{bsmt}          &      38.6885  &        3.018     &    12.818  &         0.000        &       32.770    &       44.607     \\\\\n",
       "\\textbf{garage}        &      62.7917  &        4.631     &    13.559  &         0.000        &       53.711    &       71.872     \\\\\n",
       "\\textbf{wood\\_deck}    &      38.5272  &        6.378     &     6.041  &         0.000        &       26.022    &       51.033     \\\\\n",
       "\\textbf{open\\_porch}   &      14.9671  &       12.141     &     1.233  &         0.218        &       -8.839    &       38.773     \\\\\n",
       "\\textbf{lot}           &       0.3054  &        0.104     &     2.934  &         0.003        &        0.101    &        0.510     \\\\\n",
       "\\textbf{year\\_built}   &     679.6490  &       30.102     &    22.578  &         0.000        &      620.626    &      738.672     \\\\\n",
       "\\textbf{year\\_sold}    &    -609.9535  &      576.727     &    -1.058  &         0.290        &    -1740.787    &      520.880     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1242.185 & \\textbf{  Durbin-Watson:     } &     1.454   \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 135089.991  \\\\\n",
       "\\textbf{Skew:}          &  -1.030  & \\textbf{  Prob(JB):          } &      0.00   \\\\\n",
       "\\textbf{Kurtosis:}      &  36.212  & \\textbf{  Cond. No.          } &  2.01e+07   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.01e+07. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             sale_price   R-squared:                       0.737\n",
       "Model:                            OLS   Adj. R-squared:                  0.736\n",
       "Method:                 Least Squares   F-statistic:                     907.6\n",
       "Date:                Mon, 08 Jan 2024   Prob (F-statistic):               0.00\n",
       "Time:                        15:37:58   Log-Likelihood:                -35252.\n",
       "No. Observations:                2928   AIC:                         7.052e+04\n",
       "Df Residuals:                    2918   BIC:                         7.058e+04\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept    -1.184e+05   1.16e+06     -0.102      0.919   -2.39e+06    2.16e+06\n",
       "Q(\"1st_flr\")    71.8469      3.497     20.546      0.000      64.990      78.703\n",
       "Q(\"2nd_flr\")    68.3078      2.006     34.053      0.000      64.375      72.241\n",
       "bsmt            38.6885      3.018     12.818      0.000      32.770      44.607\n",
       "garage          62.7917      4.631     13.559      0.000      53.711      71.872\n",
       "wood_deck       38.5272      6.378      6.041      0.000      26.022      51.033\n",
       "open_porch      14.9671     12.141      1.233      0.218      -8.839      38.773\n",
       "lot              0.3054      0.104      2.934      0.003       0.101       0.510\n",
       "year_built     679.6490     30.102     22.578      0.000     620.626     738.672\n",
       "year_sold     -609.9535    576.727     -1.058      0.290   -1740.787     520.880\n",
       "==============================================================================\n",
       "Omnibus:                     1242.185   Durbin-Watson:                   1.454\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           135089.991\n",
       "Skew:                          -1.030   Prob(JB):                         0.00\n",
       "Kurtosis:                      36.212   Cond. No.                     2.01e+07\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.01e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'sale_price ~ Q(\"1st_flr\") + Q(\"2nd_flr\") + bsmt + garage + wood_deck + open_porch + lot + year_built + year_sold'\n",
    "regression = smf.ols(formula = model, data = house).fit()\n",
    "regression.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
